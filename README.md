# <img height=40 src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Hand%20gestures/Waving%20Hand.png"/> Awesome-Video2Music
About Awesome-Video2Music: a curated list of Video to Music Generation

##  Paper List

### 2024
- 2024 Jul. FoleyCrafter: Bring Silent Videos to Life with Lifelike and Synchronized Sounds. Shanghai Artificial Intelligence Laboratory, Chinese University of Hong Kong, Shenzhen. [🌐 Demo](https://foleycrafter.github.io/) [🔗 Code](https://github.com/open-mmlab/FoleyCrafter);
- 2024 Jul. FRIEREN: Efficient Video-to-Audio Generation with Rectified Flow Matching. ZheJiang University. [🌐 Demo](https://frieren-v2a.github.io/)
- 2024 Jul. Masked Generative Video-to-Audio Transformers with Enhanced Synchronicity. Dolby Lab. ECCV'24. [🌐 Demo](https://maskvat.github.io/)
- 2024 June. VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling, HKUST, Microsoft Research Asia.  [🔗 Code](https://github.com/ZeyueT/VidMuse/)
- 2024 May. Visual Echoes: A Simple Unified Transformer for Audio-Visual Generation [image2audio]. [🌐 Demo](https://docs.google.com/presentation/d/1ZtC0SeblKkut4XJcRaDsSTuCRIXB3ypxmSi7HTY3IyQ/edit#slide=id.g2cca3e60f2e_1_118)
- 2024. V2Meow: Meowing to the Visual Beat via Video-to-Music Generation, Google. AAAI'24. [🔗 Code](https://google-research.github.io/noise2music/v2meow/)
- 



## Datasets

- V2M (Unpublished): VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling.
- VGGSound: Vggsound: A large-scale audio-visual dataset. ICASSP'20
- AVSync15: Audio-synchronized visual animation.
- MV100K: 

