# <img height=40 src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Hand%20gestures/Waving%20Hand.png"/> Awesome-Video2Music
About Awesome-Video2Audio: a curated list of Video to Audio Generation

##  Paper List

### 2024
- 2024 Jul. FoleyCrafter: Bring Silent Videos to Life with Lifelike and Synchronized Sounds. Shanghai Artificial Intelligence Laboratory, Chinese University of Hong Kong, Shenzhen. [🌐 Demo](https://foleycrafter.github.io/) [🔗 Code](https://github.com/open-mmlab/FoleyCrafter);
- 2024 Jul. FRIEREN: Efficient Video-to-Audio Generation with Rectified Flow Matching. ZheJiang University. [🌐 Demo](https://frieren-v2a.github.io/)
- 2024 Jul. Masked Generative Video-to-Audio Transformers with Enhanced Synchronicity. Dolby Lab. ECCV'24. [🌐 Demo](https://maskvat.github.io/)
- 2024 Jul. Read, Watch and Scream! Sound Generation from Text and Video, NAVER. [🌐 Demo](https://naver-ai.github.io/rewas/)
- 2024 June. VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling, HKUST, Microsoft Research Asia.  [🔗 Code](https://github.com/ZeyueT/VidMuse/)
- 2024 May. Visual Echoes: A Simple Unified Transformer for Audio-Visual Generation [image2audio]. [🌐 Demo](https://docs.google.com/presentation/d/1ZtC0SeblKkut4XJcRaDsSTuCRIXB3ypxmSi7HTY3IyQ/edit#slide=id.g2cca3e60f2e_1_118)
- 2024 Feb. Seeing and Hearing: Open-domain Visual-Audio Generation with Diffusion  Latent Aligners, HKUST, CVPR'24. [🌐 Demo](https://yzxing87.github.io/Seeing-and-Hearing/) [🔗 Code](https://github.com/yzxing87/Seeing-and-Hearing)
- 2024. V2Meow: Meowing to the Visual Beat via Video-to-Music Generation, Google. AAAI'24. [🔗 Code](https://google-research.github.io/noise2music/v2meow/)
- 2024 Diff-BGM: A Diffusion Model for Video Background Music Generation, PKU, CVPR'24. [🔗 Code](https://github.com/sizhelee/Diff-BGM)

### 2023
- 2023 Aug. Video Background Music Generation: Dataset, Method and Evaluation, Beihang University, ICCV'23. [🔗 Code](https://github.com/zhuole1025/SymMV)
- 2023 Feb. Discrete Contrastive Diffusion for Cross-Modal Music and Image Generation, Illinois Institute of Technology, ICLR'23. [🌐 Demo](https://l-yezhu.github.io/CDCD/) [🔗 Code](https://github.com/L-YeZhu/CDCD)
- 2023 MM-Diffusion: Learning Multi-Modal Diffusion Models for  Joint Audio and Video Generation, Renmin University of China CVPR'23. [🔗 Code](https://github.com/researchmm/MM-Diffusion)

### 2022 
- 2022 Jul. Quantized GAN for Complex  Music Generation from Dance Videos, Illinois Institute of Technology, ECCV'22. [🌐 Demo](https://l-yezhu.github.io/D2M-GAN/) [🔗 Code](https://github.com/L-YeZhu/D2M-GAN)

### 2021
- 2021 Nov. Video Background Music Generation with Controllable Music Transformer, Beihang University, MM'21. [🌐 Demo](https://wzk1015.github.io/cmt/) [🔗 Code](https://github.com/wzk1015/video-bgm-generation)

### 2020
- 2020 Jul. Generating Visually Aligned Sound from Videos, South China University of Technology, TIP'20. [🌐 Demo](https://www.youtube.com/watch?v=fI_h5mZG7bg) [🔗 Code](https://github.com/PeihaoChen/regnet) 
- 2020 Jul. Foley Music: Learning to Generate  Music from Videos, MIT.
- 2020 Jun. Audeo: Audio Generation for a Silent Performance Video, University of Washington.

### 2019
- 2019, AIST Dance Video Database: Multi-Genre, Multi-Dancer, and Multi-Camera Database for Dance Information Processing, AIST, ISMIR'19. 

### 2018
- 2018 Jun. Visual to Sound: Generating Natural Sound for Videos in the Wild, University of North Carolina, CVPR'18. 
- 2018, Visually Indicated Sound Generation by Perceptually Optimized Classification, University of Southern California, ECCV MULA workshop'18. [🔗 Code](https://github.com/kanchen-usc/VIG)

## Survey
- 2024 Aug. Foundation Models for Music: A Survey, Queen Mary University of London.
- 2024 Jun. LLMs Meet Multimodal Generation and Editing:  A Survey, HKUST. [🔗 Code](https://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation). 


## Datasets

- V2M (Unpublished): VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling.
- VGGSound: Vggsound: A large-scale audio-visual dataset. ICASSP'20
- Landscape
- TikTok Dance-Music
- AVSync15: Audio-synchronized visual animation.
- MV100K:
- BGM909: Diff-BGM: A Diffusion Model for Video Background Music Generation
- MMtrail: A Multimodal Trailer Video Dataset with Language and Music Descriptions.
- SymMV: Video Background Music Generation: Dataset, Method and Evaluation.
- [VAS](https://drive.google.com/file/d/14birixmH7vwIWKxCHI0MIWCcZyohF59g/view): Generating Visually Aligned Sound from Videos.
- [AIST++](https://google.github.io/aistplusplus_dataset/download.html)
- [AIST](https://aistdancedb.ongaaccel.jp/)

